{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9e1c66b",
   "metadata": {},
   "source": [
    "# Logistic Regression Metrics and its Formuals & Calculations:\n",
    "# =============================================================\n",
    "\n",
    "\n",
    "Below are the Metrics(comes from classification_report) to evaluate the Logistic Regression model's performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# True Positive Rate (Sensitivity or Recall of +ve class):\n",
    "\n",
    "This is the proportion of actual positive instances correctly identified by the model. It is calculated as the number    of true positives divided by the sum of true positives and false negatives.\n",
    "\n",
    "                  Sensitivity= TP/(TP + FN)\n",
    "        \n",
    "# Precision:\n",
    "\n",
    "Precesion for Positive class: It is the proportion of Actual Positives among those predicted as positive(both including TP and FP). It tells us how accurate our Positive class predictions are.\n",
    "\n",
    "                  Precision(for +ve class) = TP(TP + FP)\n",
    "\n",
    "        \n",
    "Precesion for Negative class: It is the proportion of Actual Negatives among those predicted as Negative(both including TN and FN). It tells us how accurate our Negative class predictions are.       \n",
    "                  \n",
    "                  precision(for -ve class) = TN/(TN + FN)\n",
    "      \n",
    "\n",
    "# False Positive Rate(Type I Error): \n",
    "    \n",
    "This is the proportion of actual negative instances incorrectly classified as positive by the model. It is calculated by the number of false positives divided by the sum of false positives and true negatives.\n",
    "\n",
    "                  False Positive Rate= FP/(FP + TN) or \n",
    "                  \n",
    "                  False Positive Rate= (1 - Specificity)\n",
    "\n",
    "# False Negative Rate(Type II Error):\n",
    "\n",
    "This is the proportion of actual positive instaces incorrectly classified as negative class by the model. Its caluclated  by the number of false negative divided by the sum of false negatives and troe positives.\n",
    "\n",
    "                  False Negative Rate= FN/(FN +TP)\n",
    "\n",
    "\n",
    "# True Negative Rate(Specificity or Recall of Negative class): \n",
    "      \n",
    "This is the complement of the false positive rate and represents the proportion of actual negative instances correctly     identified by the model.\n",
    "\n",
    "                  Specificity = (1 - False Positive Rate) or\n",
    "                 \n",
    "                  True Negative Rate or Specificity=  TN/ (TN + FP)\n",
    "                  \n",
    "                  \n",
    "# F1 Score: \n",
    "\n",
    "It is the harmonic mean of precision and recall. It provides a balance between precision and recall.\n",
    "\n",
    "                  F1 Score(+ve or -ve classes) =  (2 × Precision × Recall)/(Precision + Recall)\n",
    "    \n",
    "\n",
    "# Accuracy:\n",
    "\n",
    "This is the proprotion of Correct predictions to the total number of predictions.\n",
    "\n",
    "                  Accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "    \n",
    "# Support: \n",
    "\n",
    "Total number of data points in each class.\n",
    "\n",
    "# Macro Average:\n",
    "\n",
    "This is calculates the Average of Metrics(Precision, Recall & F1-score) across all classes by giving Equal Weights to each class\n",
    " \n",
    "    Binary Class:\n",
    "    -------------\n",
    "            \n",
    "                  Macro Avg of Precision = (Precision of Class_0 + Precision of Class_1)/2\n",
    "    \n",
    "                  Macro Avg of Recall = (Recall of class_0 + Recall of Class_1)/2\n",
    "        \n",
    "                  Macro avg of F1-Score= (F1-Score of class_0 + F1-score of class_1)/2\n",
    "            \n",
    "    Multiclass:\n",
    "    ------------\n",
    "    \n",
    "    \n",
    "                  Macro Avg of Precision = (Precision of Class_0 + Precision of Class_1+ ...Precision of class_n)/n\n",
    "    \n",
    "                  Macro Avg of Recall = (Recall of class_0 + Recall of Class_1+ ... Recall of class_n)/n\n",
    "        \n",
    "                  Macro avg of F1-Score= (F1-Score of class_0 + F1-score of class_1+ ...F1-score of class_n)/n\n",
    "            \n",
    "# Weighted Average:\n",
    "\n",
    "This calculates the Average of Metrics(Precision, Recall & F1-score), weighted by the support of each class. This gives the more importance to the classes those having more datapoints.\n",
    "\n",
    "\n",
    "Note: Assuming Binary Class problem.\n",
    "\n",
    "    Calculate the Precision, Recall & F1-score for the +ve class:\n",
    "    ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "                 Precision of +ve class(class_0 lets say) =   TP(TP + FP)\n",
    "                 \n",
    "                 Recall of +ve class(class_0) =  TP/(TP + FN)\n",
    "                 (aka TPR or Sensitivity)\n",
    "                 \n",
    "                 F1-score of +ve class(class_0) = (2 × Precision of +ve × Recall of +ve)/(Precisionof +ve + Recall +ve)\n",
    "                 \n",
    "\n",
    "    Calculate the Precision, Recall & F1-score for the -ve class:\n",
    "    ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "                 Precision of -ve class(class_1 lets say) =   TN(TN + FN)\n",
    "                 \n",
    "                 Recall of -ve class(class_1) = TN/(TN + FP)\n",
    "                 (aka TNR or Specificity)      \n",
    "                 \n",
    "                 F1-score of -ve class(class_1)=  (2 × Precision of -ve × Recall of -ve)/(Precisionof -ve + Recall -ve)\n",
    "                 \n",
    "    \n",
    "    Calculate the Weighted Avg of Precison, Recall & F1-score:\n",
    "    ----------------------------------------------------------\n",
    "\n",
    "\n",
    "       Weighted Avg of Precision = precision(class_0) * (support of class_0) + precision(class_1) * (support of class_1)\n",
    "                                   -------------------------------------------------------------------------------------\n",
    "                                                    (support of class_0 + support of class_1 )\n",
    "                                                    \n",
    "       \n",
    "       Weighted Avg of Recall =    Recall(class_0) * (support of class_0) + Recall(class_1) * (support of class_1)\n",
    "                                   -------------------------------------------------------------------------------------\n",
    "                                                    (support of class_0 + support of class_1 )\n",
    "                                                    \n",
    "                                                    \n",
    "       Weighted Avg of F1-score = F1-score(class_0) * (support of class_0) + F1-score(class_1) * (support of class_1)\n",
    "                                   -------------------------------------------------------------------------------------\n",
    "                                                    (support of class_0 + support of class_1 )\n",
    "    \n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa1ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
